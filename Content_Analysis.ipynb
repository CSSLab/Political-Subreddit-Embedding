{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import load_embedding, parse_tup, cos_sim, cos_dist\n",
    "from tqdm.auto import tqdm\n",
    "from datetime import datetime\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from utils import CANDIDATE_SUBS\n",
    "TIME_FRAME = \"monthly\"\n",
    "left_candidates = [\"JoeBiden\",\"SandersForPresident\",\"BaemyKlobaechar\",\"ElizabethWarren\",\"Pete_Buttigieg\",\"YangForPresidentHQ\"]\n",
    "right_candidates = [\"The_Donald\"]\n",
    "mapping = {}\n",
    "for a,b in zip(left_candidates+right_candidates,px.colors.qualitative.Plotly):\n",
    "    mapping[a] = b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------------+--------------------+\n",
      "|              author|      subreddit|                body|\n",
      "+--------------------+---------------+--------------------+\n",
      "|       flamethrower2|ElizabethWarren|According to Cohe...|\n",
      "|       rieslingatkos|ElizabethWarren|> *Without the pr...|\n",
      "|    metroidcomposite|ElizabethWarren|>Military interve...|\n",
      "|       flamethrower2|ElizabethWarren|We know Rich Dad ...|\n",
      "|             IlikeJG|ElizabethWarren|What are you even...|\n",
      "|        nyr11messier|ElizabethWarren|I was thinking th...|\n",
      "|CarolinianRevolution|ElizabethWarren|                What|\n",
      "|  RecallRethuglicans|ElizabethWarren|Bold would be pay...|\n",
      "|       marshalgivens|ElizabethWarren|Family Fun Pack f...|\n",
      "|      SANTA_OFFICIAL|ElizabethWarren|I think she shoul...|\n",
      "|      idontevenwant2|ElizabethWarren|That isn't exactl...|\n",
      "|               oiooo|ElizabethWarren|Gillibrand is my ...|\n",
      "|   starspangledxunzi|ElizabethWarren|Elizabeth Warren ...|\n",
      "|            flying87|ElizabethWarren|Meet in the middl...|\n",
      "|          eigenscape|ElizabethWarren|Republicans call ...|\n",
      "|      SANTA_OFFICIAL|ElizabethWarren|I like it. Subtle...|\n",
      "|            flying87|ElizabethWarren|Well, sort of the...|\n",
      "|            kauthonk|ElizabethWarren|No they don't. Yo...|\n",
      "|            kauthonk|ElizabethWarren|I love this.  I'l...|\n",
      "|          eigenscape|ElizabethWarren|They did. They ca...|\n",
      "+--------------------+---------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init(\"/h/224/cameron/spark-3.0.0-preview2-bin-hadoop2.7\")\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType,StringType\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "spark.sparkContext.getConf().getAll()\n",
    "\n",
    "cols = [\"author\",\"subreddit\",\"body\"]\n",
    "comments = spark.read.load(\"/comments_2019.parquet\").select(*cols)\n",
    "comments = comments.where((comments['subreddit'].rlike(\"|\".join([\"(\" + cand + \")\" for cand in [\"ElizabethWarren\"]]))) \n",
    "                          & (comments['body'] != \"[removed]\")\n",
    "                          & (comments['body'] != \"[deleted]\")\n",
    "                          & (comments[\"author\"] != \"AutoModerator\")\n",
    "                          & (comments[\"author\"] != \"[deleted]\")\n",
    "                          & ~comments[\"body\"].contains(\"www.reddit.com\"))\n",
    "\n",
    "comments.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2113252"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+---------------+--------------------+--------------------+--------------------+\n",
      "|            author|      subreddit|                body|          clean_body|     clean_tokenized|\n",
      "+------------------+---------------+--------------------+--------------------+--------------------+\n",
      "|     flamethrower2|ElizabethWarren|According to Cohe...|according cohen t...|[according, cohen...|\n",
      "|     rieslingatkos|ElizabethWarren|> *Without the pr...|without proper fr...|[without, proper,...|\n",
      "|  metroidcomposite|ElizabethWarren|>Military interve...|military interven...|[military, interv...|\n",
      "|     flamethrower2|ElizabethWarren|We know Rich Dad ...|know rich poor re...|[know, rich, poor...|\n",
      "|           IlikeJG|ElizabethWarren|What are you even...|even talking comm...|[even, talking, c...|\n",
      "|      nyr11messier|ElizabethWarren|I was thinking th...|thinking thing al...|[thinking, thing,...|\n",
      "|RecallRethuglicans|ElizabethWarren|Bold would be pay...|bold would paying...|[bold, would, pay...|\n",
      "|     marshalgivens|ElizabethWarren|Family Fun Pack f...|family pack matt ...|[family, pack, ma...|\n",
      "|    SANTA_OFFICIAL|ElizabethWarren|I think she shoul...|think free public...|[think, free, pub...|\n",
      "|    idontevenwant2|ElizabethWarren|That isn't exactl...|exactly said x200...|[exactly, said, x...|\n",
      "|             oiooo|ElizabethWarren|Gillibrand is my ...|gillibrand first ...|[gillibrand, firs...|\n",
      "| starspangledxunzi|ElizabethWarren|Elizabeth Warren ...|elizabeth warren ...|[elizabeth, warre...|\n",
      "|          flying87|ElizabethWarren|Meet in the middl...|meet middle call ...|[meet, middle, ca...|\n",
      "|        eigenscape|ElizabethWarren|Republicans call ...|republican call e...|[republican, call...|\n",
      "|    SANTA_OFFICIAL|ElizabethWarren|I like it. Subtle...|like subtle rebra...|[like, subtle, re...|\n",
      "|          flying87|ElizabethWarren|Well, sort of the...|well sort theodor...|[well, sort, theo...|\n",
      "|          kauthonk|ElizabethWarren|No they don't. Yo...|bubble think soci...|[bubble, think, s...|\n",
      "|          kauthonk|ElizabethWarren|I love this.  I'l...|love x200b progre...|[love, x200b, pro...|\n",
      "|        eigenscape|ElizabethWarren|They did. They ca...|called obama soci...|[called, obama, s...|\n",
      "|      electrobento|ElizabethWarren|Talk to people un...|talk people much ...|[talk, people, mu...|\n",
      "+------------------+---------------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.corpus import stopwords\n",
    "from pyspark.sql.types import StringType, ArrayType \n",
    "from pyspark.sql.functions import udf\n",
    "import nltk\n",
    "import re\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "def clean_comment(comment):\n",
    "    comment = comment.lower()\n",
    "    # Remove urls\n",
    "    comment = re.sub('http[s]?://\\S+', '', comment)\n",
    "    token_words = word_tokenize(comment)\n",
    "    stem_comment=[]\n",
    "    for token in token_words:\n",
    "        token = re.sub(\"[,\\.!?']\", '', token)\n",
    "        token = lemmatizer.lemmatize(token)\n",
    "        if token not in stop_words and (len(token) > 3 or token==\"joe\" or token==\"amy\"):\n",
    "            stem_comment.append(token)\n",
    "            stem_comment.append(\" \")\n",
    "    return \"\".join(stem_comment)\n",
    "\n",
    "udf_clean = udf(clean_comment,StringType())\n",
    "# Drop comments that result in an empty string \"\" after cleaning. These are comments like \"ok\", \"who?\" etc. \n",
    "comments = comments.withColumn(\"clean_body\", udf_clean(comments[\"body\"])).filter(\"clean_body != ''\")\n",
    "comments.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word clouds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for candidate in left_candidates:\n",
    "    text = comments.where(comments[\"subreddit\"] == candidate).select(\"clean_body\").rdd.flatMap(lambda x: x).collect()\n",
    "    word_cloud = WordCloud(max_font_size=200, background_color=\"white\", max_words=80,\n",
    "                        colormap=\"nipy_spectral\", stopwords=STOPWORDS).generate(' '.join(text))\n",
    "    plt.figure()\n",
    "    plt.imshow(word_cloud, interpolation=\"hermite\")\n",
    "    plt.title(\"{} Subreddit Word Cloud\\n\".format(candidate))\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout(pad=0)\n",
    "    plt.show()\n",
    "    plt.savefig(\"visualizations/wordclouds/{}_subreddit_word_cloud\".format(candidate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA Summarization \n",
    "\n",
    "Summarize the entire text corpora (all of the different subs together) + the individual candidate subreddits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "\n",
    "def create_bow(data):\n",
    "    # Create Dictionary\n",
    "    word_dict = corpora.Dictionary(data)  # Create Corpus\n",
    "    # Term Document Frequency\n",
    "    corpus = [word_dict.doc2bow(text) for text in data]\n",
    "    return corpus, word_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+---------------+--------------------+--------------------+--------------------+\n",
      "|            author|      subreddit|                body|          clean_body|     clean_tokenized|\n",
      "+------------------+---------------+--------------------+--------------------+--------------------+\n",
      "|     flamethrower2|ElizabethWarren|According to Cohe...|according cohen t...|[according, cohen...|\n",
      "|     rieslingatkos|ElizabethWarren|> *Without the pr...|without proper fr...|[without, proper,...|\n",
      "|  metroidcomposite|ElizabethWarren|>Military interve...|military interven...|[military, interv...|\n",
      "|     flamethrower2|ElizabethWarren|We know Rich Dad ...|know rich poor re...|[know, rich, poor...|\n",
      "|           IlikeJG|ElizabethWarren|What are you even...|even talking comm...|[even, talking, c...|\n",
      "|      nyr11messier|ElizabethWarren|I was thinking th...|thinking thing al...|[thinking, thing,...|\n",
      "|RecallRethuglicans|ElizabethWarren|Bold would be pay...|bold would paying...|[bold, would, pay...|\n",
      "|     marshalgivens|ElizabethWarren|Family Fun Pack f...|family pack matt ...|[family, pack, ma...|\n",
      "|    SANTA_OFFICIAL|ElizabethWarren|I think she shoul...|think free public...|[think, free, pub...|\n",
      "|    idontevenwant2|ElizabethWarren|That isn't exactl...|exactly said x200...|[exactly, said, x...|\n",
      "|             oiooo|ElizabethWarren|Gillibrand is my ...|gillibrand first ...|[gillibrand, firs...|\n",
      "| starspangledxunzi|ElizabethWarren|Elizabeth Warren ...|elizabeth warren ...|[elizabeth, warre...|\n",
      "|          flying87|ElizabethWarren|Meet in the middl...|meet middle call ...|[meet, middle, ca...|\n",
      "|        eigenscape|ElizabethWarren|Republicans call ...|republican call e...|[republican, call...|\n",
      "|    SANTA_OFFICIAL|ElizabethWarren|I like it. Subtle...|like subtle rebra...|[like, subtle, re...|\n",
      "|          flying87|ElizabethWarren|Well, sort of the...|well sort theodor...|[well, sort, theo...|\n",
      "|          kauthonk|ElizabethWarren|No they don't. Yo...|bubble think soci...|[bubble, think, s...|\n",
      "|          kauthonk|ElizabethWarren|I love this.  I'l...|love x200b progre...|[love, x200b, pro...|\n",
      "|        eigenscape|ElizabethWarren|They did. They ca...|called obama soci...|[called, obama, s...|\n",
      "|      electrobento|ElizabethWarren|Talk to people un...|talk people much ...|[talk, people, mu...|\n",
      "+------------------+---------------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, split \n",
    "comments = comments.withColumn(\"clean_tokenized\",split(col(\"clean_body\"), \" \"))\n",
    "comments.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- finding bigrams ---\n"
     ]
    }
   ],
   "source": [
    "print(\"--- finding bigrams ---\")\n",
    "text_data = comments.select(\"clean_tokenized\").rdd.flatMap(lambda x: x).collect()\n",
    "bigram = gensim.models.Phrases(text_data, min_count=8, threshold=100)\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "text_data = [bigram_mod[comment] for comment in text_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- creating BoW model ---\n"
     ]
    }
   ],
   "source": [
    "print(\"--- creating BoW model ---\")\n",
    "corpus, word_dict = create_bow(text_data)\n",
    "lda_model = gensim.models.LdaMulticore(corpus=corpus,id2word=word_dict,num_topics=5,random_state=100,chunksize=100,passes=10,per_word_topics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.035*\"warren\" + 0.020*\"bernie\" + 0.017*\"think\" + 0.015*\"like\" + 0.014*\"candidate\" + 0.011*\"would\" + 0.011*\"people\" + 0.009*\"sander\" + 0.009*\"biden\" + 0.008*\"supporter\"'),\n",
       " (1,\n",
       "  '0.016*\"poll\" + 0.014*\"state\" + 0.010*\"election\" + 0.009*\"would\" + 0.009*\"voter\" + 0.008*\"campaign\" + 0.008*\"money\" + 0.008*\"vote\" + 0.008*\"number\" + 0.007*\"primary\"'),\n",
       " (2,\n",
       "  '0.012*\"post\" + 0.010*\"comment\" + 0.010*\"article\" + 0.008*\"question\" + 0.008*\"thanks\" + 0.008*\"read\" + 0.007*\"good\" + 0.007*\"thank\" + 0.007*\"know\" + 0.006*\"like\"'),\n",
       " (3,\n",
       "  '0.025*\"people\" + 0.011*\"like\" + 0.009*\"think\" + 0.008*\"make\" + 0.007*\"thing\" + 0.007*\"would\" + 0.007*\"need\" + 0.006*\"right\" + 0.006*\"want\" + 0.005*\"policy\"'),\n",
       " (4,\n",
       "  '0.028*\"plan\" + 0.016*\"would\" + 0.009*\"cost\" + 0.009*\"healthcare\" + 0.008*\"medicare\" + 0.008*\"year\" + 0.008*\"insurance\" + 0.008*\"bill\" + 0.006*\"system\" + 0.006*\"company\"')]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_model.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
